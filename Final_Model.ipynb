{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import medfilt, welch, find_peaks\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pywt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/content/DataLoader.csv')\n",
    "\n",
    "# Map 'F' to 0 and 'M' to 1 in the 'Gender' column to make it numeric\n",
    "df['Gender'] = df['Gender'].map({'F': 0, 'M': 1})\n",
    "\n",
    "# Preprocessing\n",
    "# Convert string representations of arrays to actual lists of numbers\n",
    "df['ICA_Output'] = df['ICA_Output'].apply(eval)\n",
    "df['CHROME_Output'] = df['CHROME_Output'].apply(eval)\n",
    "df['POS_Output'] = df['POS_Output'].apply(eval)\n",
    "\n",
    "# Pad or truncate sequences to a common length\n",
    "max_length = max(len(seq) for seq in df['ICA_Output'])\n",
    "X_ica_padded = pad_sequences(df['ICA_Output'].to_list(), maxlen=max_length, padding='post', dtype='float32')\n",
    "X_chrome_padded = pad_sequences(df['CHROME_Output'].to_list(), maxlen=max_length, padding='post', dtype='float32')\n",
    "X_pos_padded = pad_sequences(df['POS_Output'].to_list(), maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "# Apply filtering, normalization, baseline correction\n",
    "filtered_ica_array = []\n",
    "filtered_chrome_array = []\n",
    "filtered_pos_array = []\n",
    "\n",
    "for signal_ica, signal_chrome, signal_pos in zip(X_ica_padded, X_chrome_padded, X_pos_padded):\n",
    "    # Apply median filtering\n",
    "    filtered_ica_signal = medfilt(signal_ica, kernel_size=3)\n",
    "    filtered_chrome_signal = medfilt(signal_chrome, kernel_size=3)\n",
    "    filtered_pos_signal = medfilt(signal_pos, kernel_size=3)\n",
    "\n",
    "    # Normalize the signals\n",
    "    normalized_ica_signal = (filtered_ica_signal - np.mean(filtered_ica_signal)) / np.std(filtered_ica_signal)\n",
    "    normalized_chrome_signal = (filtered_chrome_signal - np.mean(filtered_chrome_signal)) / np.std(filtered_chrome_signal)\n",
    "    normalized_pos_signal = (filtered_pos_signal - np.mean(filtered_pos_signal)) / np.std(filtered_pos_signal)\n",
    "\n",
    "    # Apply baseline correction if needed\n",
    "    baseline_corrected_ica_signal = normalized_ica_signal - np.mean(normalized_ica_signal)\n",
    "    baseline_corrected_chrome_signal = normalized_chrome_signal - np.mean(normalized_chrome_signal)\n",
    "    baseline_corrected_pos_signal = normalized_pos_signal - np.mean(normalized_pos_signal)\n",
    "\n",
    "    filtered_ica_array.append(baseline_corrected_ica_signal)\n",
    "    filtered_chrome_array.append(baseline_corrected_chrome_signal)\n",
    "    filtered_pos_array.append(baseline_corrected_pos_signal)\n",
    "\n",
    "filtered_ica_array = np.array(filtered_ica_array)\n",
    "filtered_chrome_array = np.array(filtered_chrome_array)\n",
    "filtered_pos_array = np.array(filtered_pos_array)\n",
    "\n",
    "# Feature Engineering: Add statistical features to the input data\n",
    "statistical_features = np.hstack([\n",
    "    np.mean(filtered_ica_array, axis=1).reshape(-1, 1),\n",
    "    np.mean(filtered_chrome_array, axis=1).reshape(-1, 1),\n",
    "    np.mean(filtered_pos_array, axis=1).reshape(-1, 1),\n",
    "    np.median(filtered_ica_array, axis=1).reshape(-1, 1),\n",
    "    np.median(filtered_chrome_array, axis=1).reshape(-1, 1),\n",
    "    np.median(filtered_pos_array, axis=1).reshape(-1, 1),\n",
    "    np.var(filtered_ica_array, axis=1).reshape(-1, 1),\n",
    "    np.var(filtered_chrome_array, axis=1).reshape(-1, 1),\n",
    "    np.var(filtered_pos_array, axis=1).reshape(-1, 1),\n",
    "    skew(filtered_ica_array, axis=1).reshape(-1, 1),\n",
    "    skew(filtered_chrome_array, axis=1).reshape(-1, 1),\n",
    "    skew(filtered_pos_array, axis=1).reshape(-1, 1),\n",
    "    kurtosis(filtered_ica_array, axis=1).reshape(-1, 1),\n",
    "    kurtosis(filtered_chrome_array, axis=1).reshape(-1, 1),\n",
    "    kurtosis(filtered_pos_array, axis=1).reshape(-1, 1)\n",
    "])\n",
    "\n",
    "# Compute frequency domain features\n",
    "frequency_features_ica = []\n",
    "frequency_features_chrome = []\n",
    "frequency_features_pos = []\n",
    "\n",
    "for signal_ica, signal_chrome, signal_pos in zip(filtered_ica_array, filtered_chrome_array, filtered_pos_array):\n",
    "    _, psd_ica = welch(signal_ica, nperseg=256)\n",
    "    _, psd_chrome = welch(signal_chrome, nperseg=256)\n",
    "    _, psd_pos = welch(signal_pos, nperseg=256)\n",
    "\n",
    "    frequency_features_ica.append([np.mean(psd_ica), np.median(psd_ica), np.max(psd_ica), np.min(psd_ica), skew(psd_ica), kurtosis(psd_ica)])\n",
    "    frequency_features_chrome.append([np.mean(psd_chrome), np.median(psd_chrome), np.max(psd_chrome), np.min(psd_chrome), skew(psd_chrome), kurtosis(psd_chrome)])\n",
    "    frequency_features_pos.append([np.mean(psd_pos), np.median(psd_pos), np.max(psd_pos), np.min(psd_pos), skew(psd_pos), kurtosis(psd_pos)])\n",
    "\n",
    "frequency_features_ica = np.array(frequency_features_ica)\n",
    "frequency_features_chrome = np.array(frequency_features_chrome)\n",
    "frequency_features_pos = np.array(frequency_features_pos)\n",
    "\n",
    "# Wavelet Transform features\n",
    "def wavelet_features(signal, max_length=6):\n",
    "    coeffs, _ = pywt.cwt(signal, np.arange(1, 128), 'morl')\n",
    "    # Extract features from the coefficients\n",
    "    mean_coeff = np.mean(coeffs, axis=1)\n",
    "    median_coeff = np.median(coeffs, axis=1)\n",
    "    max_coeff = np.max(coeffs, axis=1)\n",
    "    min_coeff = np.min(coeffs, axis=1)\n",
    "    skewness_coeff = skew(coeffs, axis=1)\n",
    "    kurtosis_coeff = kurtosis(coeffs, axis=1)\n",
    "    # Pad or truncate features to a fixed length\n",
    "    padded_features = [mean_coeff, median_coeff, max_coeff, min_coeff, skewness_coeff, kurtosis_coeff]\n",
    "    padded_features = [np.pad(f, (0, max_length - len(f)), mode='constant') if len(f) < max_length else f[:max_length] for f in padded_features]\n",
    "    return np.array(padded_features)\n",
    "\n",
    "wavelet_features_list_ica = [wavelet_features(seq) for seq in filtered_ica_array]\n",
    "wavelet_features_list_chrome = [wavelet_features(seq) for seq in filtered_chrome_array]\n",
    "wavelet_features_list_pos = [wavelet_features(seq) for seq in filtered_pos_array]\n",
    "\n",
    "wavelet_features_array_ica = np.array(wavelet_features_list_ica)\n",
    "wavelet_features_array_chrome = np.array(wavelet_features_list_chrome)\n",
    "wavelet_features_array_pos = np.array(wavelet_features_list_pos)\n",
    "\n",
    "# Combine all features\n",
    "X_features = np.hstack([statistical_features, frequency_features_ica, frequency_features_chrome, frequency_features_pos])\n",
    "\n",
    "# Add age and gender to features\n",
    "X_with_age_gender = np.hstack([X_features, df[['Age', 'Gender']].values])\n",
    "\n",
    "# Split the data into features and targets\n",
    "y_sys = df['BP_Sys']\n",
    "y_dia = df['BP_Dia']\n",
    "\n",
    "# Split into training and testing sets for systolic\n",
    "X_train_sys, X_test_sys, y_train_sys, y_test_sys = train_test_split(X_with_age_gender, y_sys, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomForestRegressor with default hyperparameters for systolic\n",
    "rf_sys = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search for RandomForestRegressor for systolic\n",
    "rf_param_grid_sys = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "rf_grid_search_sys = GridSearchCV(estimator=rf_sys, param_grid=rf_param_grid_sys, scoring='neg_mean_absolute_error', cv=5)\n",
    "rf_grid_search_sys.fit(X_train_sys, y_train_sys)\n",
    "best_rf_sys = rf_grid_search_sys.best_estimator_\n",
    "\n",
    "# Initialize GradientBoostingRegressor for systolic\n",
    "gb_sys = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "gb_param_grid_sys = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform grid search for GradientBoostingRegressor for systolic\n",
    "gb_grid_search_sys = GridSearchCV(estimator=gb_sys, param_grid=gb_param_grid_sys, scoring='neg_mean_absolute_error', cv=5)\n",
    "gb_grid_search_sys.fit(X_train_sys, y_train_sys)\n",
    "best_gb_sys = gb_grid_search_sys.best_estimator_\n",
    "\n",
    "# Combine RandomForestRegressor and GradientBoostingRegressor predictions for systolic\n",
    "ensemble_preds_sys = (best_rf_sys.predict(X_test_sys) + best_gb_sys.predict(X_test_sys)) / 2.0\n",
    "\n",
    "# Calculate ensemble MAE for systolic prediction\n",
    "ensemble_mae_sys = mean_absolute_error(y_test_sys, ensemble_preds_sys)\n",
    "print(\"Ensemble MAE (Sys):\", ensemble_mae_sys)\n",
    "\n",
    "# Split into training and testing sets for diastolic\n",
    "X_train_dia, X_test_dia, y_train_dia, y_test_dia = train_test_split(X_with_age_gender, y_dia, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomForestRegressor with default hyperparameters for diastolic\n",
    "rf_dia = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search for RandomForestRegressor for diastolic\n",
    "rf_param_grid_dia = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "rf_grid_search_dia = GridSearchCV(estimator=rf_dia, param_grid=rf_param_grid_dia, scoring='neg_mean_absolute_error', cv=5)\n",
    "rf_grid_search_dia.fit(X_train_dia, y_train_dia)\n",
    "best_rf_dia = rf_grid_search_dia.best_estimator_\n",
    "\n",
    "# Initialize GradientBoostingRegressor for diastolic\n",
    "gb_dia = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "gb_param_grid_dia = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform grid search for GradientBoostingRegressor for diastolic\n",
    "gb_grid_search_dia = GridSearchCV(estimator=gb_dia, param_grid=gb_param_grid_dia, scoring='neg_mean_absolute_error', cv=5)\n",
    "gb_grid_search_dia.fit(X_train_dia, y_train_dia)\n",
    "best_gb_dia = gb_grid_search_dia.best_estimator_\n",
    "\n",
    "# Combine RandomForestRegressor and GradientBoostingRegressor predictions for diastolic\n",
    "ensemble_preds_dia = (best_rf_dia.predict(X_test_dia) + best_gb_dia.predict(X_test_dia)) / 2.0\n",
    "\n",
    "# Calculate ensemble MAE for diastolic prediction\n",
    "ensemble_mae_dia = mean_absolute_error(y_test_dia, ensemble_preds_dia)\n",
    "print(\"Ensemble MAE (Dia):\", ensemble_mae_dia)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
